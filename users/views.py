from inspect import Parameter
from unittest import result
from django.shortcuts import render, redirect
from django.contrib.auth.forms import UserCreationForm
from django.urls import clear_script_prefix
from .forms import UserRegisterForm
from django.contrib import messages
from django.contrib.auth.decorators import login_required
import joblib 
import pandas as pd 
import re
# for malware
import os
import tempfile
from keras.models import load_model
from pandas import DataFrame
import atexit



from sklearn.feature_extraction.text import TfidfVectorizer


def home(request):
    return render(request, 'users/home.html')


def discover(request):
    return render(request, 'users/discover.html')


def about(request):
    return render(request, 'users/aboutus.html')

def register(request):
    if request.method == "POST":
        form = UserRegisterForm(request.POST)
        if form.is_valid():
            form.save()
            username = form.cleaned_data.get('username')
            messages.success(request, f'Hi {username}, your account was created successfully')
            return redirect('home')
    else:
        form = UserRegisterForm()

    return render(request, 'users/register.html', {'form': form})


@login_required()
def profile(request):
    return render(request, 'users/profile.html')

# NEWLY ADDED
@login_required()
def maliciousURL(request):
    return render (request, 'users/maliciousURL.html')

# newly added
@login_required 
def malware(request):
    return render(request, 'users/malware.html')




#---------- STREAMLIT APP FOR MALWARE DETECTION-----------

def launch_streamlit(request):
    # Launch Streamlit app as a subprocess
    # subprocess.Popen(['streamlit', 'run', 'users/dataVis.py', 'users/Numeric columns.txt', 'users/Semi-categorical columns.txt'])

    # Render the HTML template
    return render(request, 'users/streamlit.html')



# --------- DEPLOYMENT OF MALICIOUS URLS--------------


from .tokenizer import tokenizer

def predict_malicious(request):
      
    vectorizer = joblib.load('vectorizer.sav')
    # vectorizer, tokenizer = joblib.load('vectorizer_and_tokenizer.pkl')

    if request.method == "POST":
        url = request.POST.get("url")

        tokens = tokenizer(url)

        # Vectorize the URL
        vector = vectorizer.transform(tokens)


        # import the ML model
        model = joblib.load('RF_MODEL_URL-newDataset.sav')


        # Make a prediction using the model
        prediction = model.predict(vector)[0]
        

    return render(request, 'users/result.html', {"prediction": prediction})




#----------- -------- DEPLOYMENT OF MALWARE------------------------------

from .Feature_extractor_no_arg_1676527660 import extract_infos
ANN_MODEL_NAME = 'AdaDelta_100_epochs_softmax_FINAL_1676527660.h5'
model = load_model(ANN_MODEL_NAME)
transformer = joblib.load('Data_transformer_Scaler_KB_PCA.sav')

def predict_malware(request):
    def delete_temp_file(temp_file):
        try:
            os.remove(temp_file.name)
        except:
            pass

    if request.method == 'POST':
        # Get the uploaded file
        uploaded_file = request.FILES['file']

        # Save the file to a temporary directory
        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
            for chunk in uploaded_file.chunks():
                temp_file.write(chunk)
        
        # Schedule the temporary file for deletion when the program exits
        atexit.register(delete_temp_file, temp_file)

        # Extract features from the file
        features = extract_infos(temp_file.name)
        file_info_df = DataFrame(features, index=[0])

        #transform the data using transfomer 
        transformed_data = transformer.transform(file_info_df)
        
        # Make a prediction with the model
        prediction = model.predict(transformed_data)[0]
        malware_probability = model.predict(transformed_data)[0][0] * 100
        legit_probability = model.predict(transformed_data)[0][1] * 100
        
        if legit_probability < 50.0:
            predicted_class = 'malware'
        else:
            predicted_class = 'legitimate'
            
        print(predicted_class)
        print(legit_probability)
        

        # to_return = {
        # 'predicted_class' : prediction[0],
        # 'malware_prob' : round(prediction[0][0], 4) * 100
        # }

        # temp_file.close()

        # # os.remove(temp_file.name)

        # # Delete the temporary file
        # os.unlink(temp_file.name)   

    return render(request, 'users/resultMalware.html', {'predicted_class': predicted_class, 'malware_probability': round(malware_probability, 2),'legit_probability': round(legit_probability, 2) })